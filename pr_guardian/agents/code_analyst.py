"""
Agent 1 ‚Äî GitHub Code Analyst (LLM-powered).

Analyse le diff de la PR via Cohere LLM pour :
- Lister les fichiers modifi√©s et leur nature
- D√©tecter les fonctionnalit√©s impl√©ment√©es
- Identifier endpoints, classes, m√©thodes, migrations
- √âvaluer la couverture de tests
- Rep√©rer les points sensibles (s√©curit√©, perf, DB)
- Analyser qualit√©, s√©curit√©, bugs, architecture (via IA)

Phase 1 : extraction statique (regex, parsing)
Phase 2 : analyse LLM s√©mantique (Cohere)
"""

from __future__ import annotations

import json
import logging
from typing import Any

import cohere

from pr_guardian.agents.base_agent import BaseAgent
from pr_guardian.config import get_settings
from pr_guardian.integrations.github_client import GitHubClient
from pr_guardian.models import CodeAnalysisResult, ModifiedFile, PRContext
from pr_guardian.parsers.diff_parser import DiffParser
from pr_guardian.utils.helpers import extract_language

logger = logging.getLogger("pr_guardian.agent.CodeAnalyst")

# ‚îÄ‚îÄ Prompt syst√®me pour l'analyse de code ‚îÄ‚îÄ

CODE_ANALYST_SYSTEM_PROMPT = """\
Tu es un expert en revue de code. Tu re√ßois le diff d'une Pull Request.

Ton r√¥le : analyser le code en profondeur et fournir une √©valuation experte.

ANALYSE REQUISE :
1. **Qualit√© du code** : lisibilit√©, respect des conventions, DRY, SOLID
2. **S√©curit√©** : failles potentielles (injection, XSS, auth bypass, secrets expos√©s)
3. **Performance** : requ√™tes N+1, boucles co√ªteuses, m√©moire, concurrence
4. **Architecture** : patterns utilis√©s, couplage, responsabilit√©s
5. **Tests** : couverture suffisante, cas limites test√©s, tests fragiles
6. **Bugs potentiels** : race conditions, null pointers, edge cases, typos logiques

Tu dois r√©pondre UNIQUEMENT en JSON valide avec cette structure :
{
  "quality_score": <int 0-100>,
  "security_issues": ["description de chaque probl√®me de s√©curit√©"],
  "performance_issues": ["description de chaque probl√®me de performance"],
  "architecture_notes": ["observation sur l'architecture"],
  "bug_risks": ["description de chaque risque de bug"],
  "suggestions": ["suggestion d'am√©lioration concr√®te"],
  "summary": "r√©sum√© en 2-3 phrases de l'analyse"
}
"""


class CodeAnalystAgent(BaseAgent):
    """Agent 1 : analyse le code de la PR (statique + LLM)."""

    name = "CodeAnalyst"

    def __init__(self, github_client: GitHubClient | None = None):
        super().__init__()
        self._gh = github_client
        self._settings = get_settings()

    def _get_github(self) -> GitHubClient:
        if self._gh is None:
            self._gh = GitHubClient()
        return self._gh

    async def run(self, context: PRContext, **kwargs: Any) -> CodeAnalysisResult:
        self._log_start(context)

        gh = self._get_github()
        files = gh.get_modified_files(context.repo, context.pr_number)

        result = CodeAnalysisResult(
            files_modified=files,
            raw_diff_stats={
                "total_files": len(files),
                "total_additions": sum(f.additions for f in files),
                "total_deletions": sum(f.deletions for f in files),
            },
        )

        all_classes: list[str] = []
        all_methods: list[str] = []
        all_endpoints: list[str] = []
        features: list[str] = []
        tests_added: list[str] = []
        tests_modified: list[str] = []
        migrations: list[str] = []
        sensitive: list[str] = []
        all_patches: list[str] = []

        for f in files:
            lang = extract_language(f.filename)
            f.language = lang

            # Parser le diff
            if f.patch:
                diff_info = DiffParser.parse_patch(f.patch, f.filename)
                all_classes.extend(diff_info.classes_modified)
                all_methods.extend(diff_info.functions_modified)
                all_endpoints.extend(diff_info.endpoints_detected)
                all_patches.append(f"--- {f.filename} ---\n{f.patch}")

            # Cat√©goriser le fichier
            lower = f.filename.lower()

            # Tests
            if "test" in lower or "spec" in lower:
                if f.status == "added":
                    tests_added.append(f.filename)
                else:
                    tests_modified.append(f.filename)

            # Migrations
            if "migration" in lower or "alembic" in lower or "flyway" in lower:
                migrations.append(f.filename)

            # Points sensibles
            if any(kw in lower for kw in ("auth", "security", "password", "token", "secret",
                                           "payment", "billing", "crypto")):
                sensitive.append(f"‚ö†Ô∏è Fichier sensible : {f.filename}")

            # D√©tection de features par nom de fichier / chemin
            if f.status == "added" and lang in ("python", "java", "typescript", "javascript"):
                features.append(f"Nouveau fichier : {f.filename}")

        result.classes_touched = list(set(all_classes))
        result.methods_touched = list(set(all_methods))
        result.endpoints = list(set(all_endpoints))
        result.features_detected = features
        result.tests_added = tests_added
        result.tests_modified = tests_modified
        result.migrations_detected = migrations
        result.sensitive_points = sensitive

        # ‚îÄ‚îÄ Phase 2 : Analyse LLM s√©mantique ‚îÄ‚îÄ
        llm_analysis = None
        if self._settings.llm_configured and all_patches:
            llm_analysis = self._llm_analyze(all_patches, context)

        # R√©sum√© enrichi
        result.summary = self._build_summary(result, llm_analysis)
        result.test_coverage_info = self._assess_test_coverage(result)

        self._log_done(context)
        return result

    def _llm_analyze(self, patches: list[str], context: PRContext) -> dict | None:
        """Appelle Cohere pour une analyse s√©mantique approfondie du diff."""
        try:
            combined_diff = "\n\n".join(patches)
            if len(combined_diff) > 8000:
                combined_diff = combined_diff[:8000] + "\n\n[... diff tronqu√© ...]"

            user_message = (
                f"Analyse cette Pull Request :\n"
                f"Repo: {context.repo}, PR #{context.pr_number}\n"
                f"Titre: {context.pr_title}\n\n"
                f"## DIFF\n```\n{combined_diff}\n```"
            )

            client = cohere.ClientV2(api_key=self._settings.cohere_api_key)
            response = client.chat(
                model=self._settings.cohere_model,
                messages=[
                    {"role": "system", "content": CODE_ANALYST_SYSTEM_PROMPT},
                    {"role": "user", "content": user_message},
                ],
                max_tokens=2048,
                temperature=0.1,
                response_format={"type": "json_object"},
            )

            raw = response.message.content[0].text if response.message.content else "{}"
            analysis = json.loads(raw)
            logger.info("[CodeAnalyst] LLM analysis OK ‚Äî quality score: %s/100",
                        analysis.get("quality_score", "?"))
            return analysis

        except Exception as exc:
            logger.warning("[CodeAnalyst] LLM analysis failed: %s", exc)
            return None

    @staticmethod
    def _build_summary(r: CodeAnalysisResult, llm: dict | None = None) -> str:
        lines = [
            f"üìä **{r.raw_diff_stats.get('total_files', 0)}** fichiers modifi√©s "
            f"(+{r.raw_diff_stats.get('total_additions', 0)} / "
            f"-{r.raw_diff_stats.get('total_deletions', 0)})",
        ]
        if r.endpoints:
            lines.append(f"üîó Endpoints : {', '.join(r.endpoints)}")
        if r.classes_touched:
            lines.append(f"üèóÔ∏è Classes : {', '.join(r.classes_touched)}")
        if r.migrations_detected:
            lines.append(f"üóÉÔ∏è Migrations : {', '.join(r.migrations_detected)}")
        if r.sensitive_points:
            lines.append(f"üîí Points sensibles : {len(r.sensitive_points)}")

        # ‚îÄ‚îÄ Enrichissement LLM ‚îÄ‚îÄ
        if llm:
            lines.append(f"\nü§ñ **Analyse IA (score qualit√© : {llm.get('quality_score', '?')}/100)**")
            if llm.get("summary"):
                lines.append(f"   {llm['summary']}")
            if llm.get("security_issues"):
                lines.append(f"   üî¥ S√©curit√© : {len(llm['security_issues'])} probl√®me(s)")
                for issue in llm["security_issues"][:3]:
                    lines.append(f"      ‚Ä¢ {issue}")
            if llm.get("bug_risks"):
                lines.append(f"   üêõ Risques de bugs : {len(llm['bug_risks'])}")
                for bug in llm["bug_risks"][:3]:
                    lines.append(f"      ‚Ä¢ {bug}")
            if llm.get("performance_issues"):
                lines.append(f"   ‚ö° Performance : {len(llm['performance_issues'])} probl√®me(s)")
            if llm.get("suggestions"):
                lines.append("   üí° Suggestions :")
                for sug in llm["suggestions"][:3]:
                    lines.append(f"      ‚Ä¢ {sug}")

        return "\n".join(lines)

    @staticmethod
    def _assess_test_coverage(r: CodeAnalysisResult) -> str:
        src_files = [f for f in r.files_modified
                     if "test" not in f.filename.lower() and "spec" not in f.filename.lower()]
        test_files = r.tests_added + r.tests_modified
        if not src_files:
            return "Aucun fichier source modifi√©."
        if not test_files:
            return "‚ö†Ô∏è Aucun test ajout√©/modifi√© pour cette PR."
        ratio = len(test_files) / len(src_files) * 100
        return f"Tests : {len(test_files)} fichier(s) test pour {len(src_files)} source(s) ({ratio:.0f}%)"
